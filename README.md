# RAG-with-Langchain
A Retrieval-Augmented Generation (RAG) pipeline built with LangChain, HuggingFace embeddings, Milvus vector database, and Granite LLM (via Replicate API) for contextual question answering. This project demonstrates document ingestion, vector similarity search, and LLM-based response generation for accurate and scalable AI solutions.
